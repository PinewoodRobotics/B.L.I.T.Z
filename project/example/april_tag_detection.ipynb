{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Start the recognition server\n",
        "Before doing anything we need to start the recognition server. In order to actually start processing the messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nimport threading\\nimport subprocess\\n\\ndef run_shell_script():\\n    subprocess.run([\\'bash\\', \\'../recognition/detection/image-recognition/src/main.py\\'])\\n\\nthread = threading.Thread(target=run_shell_script)\\nthread.start()\\n\\nprint(\"Shell script finished execution.\")\\n'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "import threading\n",
        "import subprocess\n",
        "\n",
        "def run_shell_script():\n",
        "    subprocess.run(['bash', '../recognition/detection/image-recognition/src/main.py'])\n",
        "\n",
        "thread = threading.Thread(target=run_shell_script)\n",
        "thread.start()\n",
        "\n",
        "print(\"Shell script finished execution.\")\n",
        "'''\n",
        "\n",
        "# TODO: fix this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### We first import the relevant libraries that we have installed with pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import time\n",
        "import cv2\n",
        "import nats\n",
        "import numpy as np\n",
        "from nats.aio.msg import Msg\n",
        "import nest_asyncio\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### We then import the project libraries that we will be using.\n",
        "These are all from /common/ and /generated/ folders as they are the ones that are being shared in the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "from project.generated.project.common.proto.Inference_pb2 import InferenceList\n",
        "from project.common import profiler\n",
        "from project.common.config_class.profiler import ProfilerConfig\n",
        "from project.generated.project.common.proto.Image_pb2 import ImageMessage\n",
        "from project.generated.project.common.proto.Inference_pb2 import Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We do \"nest_asyncio.apply\" in order to enable awaiting in the notebook environment. Otherwise, our nats server would not work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Making a render util function\n",
        "We make a function to draw a bounding box, given x,y coordinates [the Inference message] in order to easily visualize the detections. \n",
        "\n",
        "This is also partly done since, in the future, we will need to render text, distance... etc. This will cluster our main code function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def render_detections(frame: np.ndarray, inference: Inference):\n",
        "    for i in range(0, len(inference.bounding_box), 4):\n",
        "        box = inference.bounding_box[i:i+4]\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        \n",
        "        cv2.rectangle(\n",
        "            frame,\n",
        "            (x1, y1),\n",
        "            (x2, y2),\n",
        "            color=(0, 255, 0),\n",
        "            thickness=2\n",
        "        )\n",
        "        \n",
        "        # Add label with confidence\n",
        "        label = f\"{inference.class_name}: {inference.confidence:.2f}\"\n",
        "        cv2.putText(\n",
        "            frame,\n",
        "            label,\n",
        "            (x1, y1 - 10),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            0.5,\n",
        "            (0, 255, 0),\n",
        "            2\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Initiate the global variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Video Capture and NATS connection\n",
        "The nats connection basically connects to the server, and the video capture connects to the webcam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "nats: encountered error\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/godbrigero/Documents/BLITZ/.venv/lib/python3.12/site-packages/nats/aio/client.py\", line 2117, in _read_loop\n",
            "    await self._ps.parse(b)\n",
            "  File \"/Users/godbrigero/Documents/BLITZ/.venv/lib/python3.12/site-packages/nats/protocol/parser.py\", line 157, in parse\n",
            "    await self.nc._process_pong()\n",
            "  File \"/Users/godbrigero/Documents/BLITZ/.venv/lib/python3.12/site-packages/nats/aio/client.py\", line 1597, in _process_pong\n",
            "    future.set_result(True)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/futures.py\", line 260, in set_result\n",
            "    raise exceptions.InvalidStateError(f'{self._state}: {self!r}')\n",
            "asyncio.exceptions.InvalidStateError: CANCELLED: <Future cancelled>\n"
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "nt = await nats.connect(\"nats://localhost:4222\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Queue and Image ID map\n",
        "We use a queue to store the incoming inference messages, and an image id map to store the images that we will be rendering. This is done due to the fact that the image is not available until the inference is processed <- which can take some time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "queue = asyncio.Queue()\n",
        "image_id_map = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Making the on subscribe event function\n",
        "This function is called whenever we receive a message from the nats server. We simply put the inference message in the queue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def on_message(msg: Msg):\n",
        "    await queue.put(InferenceList.FromString(msg.data))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Subscribe to the NATS topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<nats.aio.subscription.Subscription at 0x16997da90>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await nt.subscribe(\"recognition/image_output\", cb=on_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Main loop\n",
        "This is the main loop of the program. It will read the webcam, send the image to the server, and render the detections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "ename": "CancelledError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[36], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m image_id_map[image_id] \u001b[38;5;241m=\u001b[39m frame\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m nt\u001b[38;5;241m.\u001b[39mpublish(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecognition/image_input\u001b[39m\u001b[38;5;124m\"\u001b[39m, msg\u001b[38;5;241m.\u001b[39mSerializeToString())\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m nt\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m queue\u001b[38;5;241m.\u001b[39mempty():\n\u001b[1;32m     26\u001b[0m     inference \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m queue\u001b[38;5;241m.\u001b[39mget()\n",
            "File \u001b[0;32m~/Documents/BLITZ/.venv/lib/python3.12/site-packages/nats/aio/client.py:1131\u001b[0m, in \u001b[0;36mClient.flush\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_ping(future)\n\u001b[0;32m-> 1131\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwait_for(future, timeout)\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mTimeoutError:\n\u001b[1;32m   1133\u001b[0m     future\u001b[38;5;241m.\u001b[39mcancel()\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:520\u001b[0m, in \u001b[0;36mwait_for\u001b[0;34m(fut, timeout)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m timeouts\u001b[38;5;241m.\u001b[39mtimeout(timeout):\n\u001b[0;32m--> 520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/futures.py:287\u001b[0m, in \u001b[0;36mFuture.__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncio_future_blocking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mawait wasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt used with future\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:385\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 385\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/futures.py:198\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m _CANCELLED:\n\u001b[1;32m    197\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_cancelled_error()\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m!=\u001b[39m _FINISHED:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mInvalidStateError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResult is not ready.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mCancelledError\u001b[0m: "
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        continue\n",
        "\n",
        "    _, compressed_image = cv2.imencode(\".jpg\", frame)\n",
        "    \n",
        "    image_id = random.randint(0, 1000000)\n",
        "\n",
        "    msg = ImageMessage(\n",
        "        image=compressed_image.tobytes(),\n",
        "        camera_name=\"camera0\",\n",
        "        is_gray=False,\n",
        "        id=image_id,\n",
        "        height=frame.shape[0],\n",
        "        width=frame.shape[1],\n",
        "        timestamp=int(time.time() * 1000),\n",
        "    )\n",
        "\n",
        "    image_id_map[image_id] = frame\n",
        "\n",
        "    await nt.publish(\"recognition/image_input\", msg.SerializeToString())\n",
        "    await nt.flush()\n",
        "\n",
        "    if not queue.empty():\n",
        "        inference = await queue.get()\n",
        "        for inference in inference.inferences:\n",
        "            render_detections(image_id_map[image_id], inference)\n",
        "            \n",
        "        cv2.imshow(\"frame\", image_id_map[image_id])\n",
        "        cv2.waitKey(1)\n",
        "        image_id_map.pop(image_id)\n",
        "    \n",
        "    time.sleep(0.02)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
