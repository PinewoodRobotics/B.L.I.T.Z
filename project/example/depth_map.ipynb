{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import cv2\n",
    "import nats\n",
    "import numpy as np\n",
    "from nats.aio.msg import Msg\n",
    "import nest_asyncio\n",
    "import random\n",
    "from asyncio import CancelledError\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from project.generated.project.common.proto.Inference_pb2 import InferenceList\n",
    "from project.common import profiler\n",
    "from project.common.config_class.profiler import ProfilerConfig\n",
    "from project.generated.project.common.proto.Image_pb2 import ImageMessage\n",
    "from project.generated.project.common.proto.Inference_pb2 import Inference\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ImageWithParams:\n",
    "    frame: np.ndarray\n",
    "    camera_matrix: np.ndarray\n",
    "    dist_coeff: np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(frame_one: ImageWithParams, frame_two: ImageWithParams, inference: Inference):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_detections(frame: np.ndarray, inference: Inference):\n",
    "    for i in range(0, len(inference.bounding_box), 4):\n",
    "        box = inference.bounding_box[i:i+4]\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        \n",
    "        cv2.rectangle(\n",
    "            frame,\n",
    "            (x1, y1),\n",
    "            (x2, y2),\n",
    "            color=(0, 255, 0),\n",
    "            thickness=2\n",
    "        )\n",
    "        \n",
    "        # Add label with confidence\n",
    "        label = f\"{inference.class_name}: {inference.confidence:.2f}\"\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            label,\n",
    "            (x1, y1 - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "nt = await nats.connect(\"nats://localhost:4222\")\n",
    "\n",
    "queue = asyncio.Queue()\n",
    "image_id_map = {}\n",
    "\n",
    "total_time_per_image = 0\n",
    "total_images = 0\n",
    "last_reset_time = 40\n",
    "\n",
    "max_frame_age = 0.1\n",
    "cur_frame_clean_time = 40\n",
    "\n",
    "async def on_message(msg: Msg):\n",
    "    await queue.put(InferenceList.FromString(msg.data))\n",
    "\n",
    "await nt.subscribe(\"recognition/image_output\", cb=on_message)\n",
    "\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        if cur_frame_clean_time > 30:\n",
    "            cur_frame_clean_time = 0\n",
    "            for image_id in image_id_map:\n",
    "                if time.time() - image_id_map[image_id][\"timestamp\"] > max_frame_age:\n",
    "                    image_id_map.pop(image_id)\n",
    "            \n",
    "        if abs(time.time() - last_reset_time) > 5:\n",
    "            total_time_per_image = 0\n",
    "            total_images = 0\n",
    "            last_reset_time = time.time()\n",
    "\n",
    "        total_images += 1\n",
    "            \n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        _, compressed_image = cv2.imencode(\".jpg\", frame)\n",
    "        \n",
    "        image_id = random.randint(0, 1000000)\n",
    "\n",
    "        msg = ImageMessage(\n",
    "            image=compressed_image.tobytes(),\n",
    "            camera_name=\"camera0\",\n",
    "            is_gray=False,\n",
    "            id=image_id,\n",
    "            height=frame.shape[0],\n",
    "            width=frame.shape[1],\n",
    "            timestamp=int(time.time() * 1000),\n",
    "        )\n",
    "\n",
    "        image_id_map[image_id] = {\"frame\": frame, \"timestamp\": time.time()}\n",
    "\n",
    "        await nt.publish(\"recognition/image_input\", msg.SerializeToString())\n",
    "        await nt.flush()\n",
    "\n",
    "        if not queue.empty() and image_id in image_id_map:\n",
    "            inference = await queue.get()\n",
    "            for inference in inference.inferences:\n",
    "                render_detections(image_id_map[image_id][\"frame\"], inference)\n",
    "                \n",
    "            cv2.imshow(\"frame\", image_id_map[image_id][\"frame\"])\n",
    "            cv2.waitKey(1)\n",
    "            total_time_per_image += time.time() - image_id_map[image_id][\"timestamp\"]\n",
    "            image_id_map.pop(image_id)\n",
    "        \n",
    "        time.sleep(total_time_per_image / total_images if total_images > 0 else 0.02)\n",
    "except KeyboardInterrupt as e:\n",
    "    print(\"Exiting...\")\n",
    "except CancelledError as e:\n",
    "    print(\"Exiting...\")\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
