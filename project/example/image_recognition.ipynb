{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start the recognition server\n",
    "Before doing anything we need to start the recognition server. In order to actually start processing the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport threading\\nimport subprocess\\n\\ndef run_shell_script():\\n    subprocess.run([\\'bash\\', \\'python ../recognition/detection/image-recognition/src/main.py\\'])\\n\\nthread = threading.Thread(target=run_shell_script)\\nthread.start()\\n\\nprint(\"Shell script finished execution.\")\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import threading\n",
    "import subprocess\n",
    "\n",
    "def run_shell_script():\n",
    "    subprocess.run(['bash', 'python ../recognition/detection/image-recognition/src/main.py'])\n",
    "\n",
    "thread = threading.Thread(target=run_shell_script)\n",
    "thread.start()\n",
    "\n",
    "print(\"Shell script finished execution.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We first import the relevant libraries that we have installed with pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import cv2\n",
    "import nats\n",
    "import numpy as np\n",
    "from nats.aio.msg import Msg\n",
    "import nest_asyncio\n",
    "import random\n",
    "from asyncio import CancelledError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We then import the project libraries that we will be using.\n",
    "These are all from /common/ and /generated/ folders as they are the ones that are being shared in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generated.Inference_pb2 import InferenceList\n",
    "from generated.Image_pb2 import ImageMessage\n",
    "from generated.Inference_pb2 import Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do \"nest_asyncio.apply\" in order to enable awaiting in the notebook environment. Otherwise, our nats server would not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a render util function\n",
    "We make a function to draw a bounding box, given x,y coordinates [the Inference message] in order to easily visualize the detections. \n",
    "\n",
    "This is also partly done since, in the future, we will need to render text, distance... etc. This will cluster our main code function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_detections(frame: np.ndarray, inference: Inference):\n",
    "    for i in range(0, len(inference.bounding_box), 4):\n",
    "        box = inference.bounding_box[i:i+4]\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        \n",
    "        cv2.rectangle(\n",
    "            frame,\n",
    "            (x1, y1),\n",
    "            (x2, y2),\n",
    "            color=(0, 255, 0),\n",
    "            thickness=2\n",
    "        )\n",
    "        \n",
    "        # Add label with confidence\n",
    "        label = f\"{inference.class_name}: {inference.confidence:.2f}\"\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            label,\n",
    "            (x1, y1 - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate the global variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Video Capture and NATS connection\n",
    "The nats connection basically connects to the server, and the video capture connects to the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "nt = await nats.connect(\"nats://localhost:4222\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Queue and Image ID map\n",
    "We use a queue to store the incoming inference messages, and an image id map to store the images that we will be rendering. This is done due to the fact that the image is not available until the inference is processed <- which can take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = asyncio.Queue()\n",
    "image_id_map = {}\n",
    "\n",
    "total_time_per_image = 0\n",
    "total_images = 0\n",
    "last_reset_time = 40\n",
    "\n",
    "max_frame_age = 0.1\n",
    "cur_frame_clean_time = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the on subscribe event function\n",
    "This function is called whenever we receive a message from the nats server. We simply put the inference message in the queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def on_message(msg: Msg):\n",
    "    await queue.put(InferenceList.FromString(msg.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subscribe to the NATS topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nats.aio.subscription.Subscription at 0x11fbdd400>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await nt.subscribe(\"recognition/image_output\", cb=on_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main loop\n",
    "This is the main loop of the program. It will read the webcam, send the image to the server, and render the detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Sent image to server\n",
      "Exiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nats: encountered error\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/godbrigero/Documents/BLITZ/.venv/lib/python3.12/site-packages/nats/aio/client.py\", line 2117, in _read_loop\n",
      "    await self._ps.parse(b)\n",
      "  File \"/Users/godbrigero/Documents/BLITZ/.venv/lib/python3.12/site-packages/nats/protocol/parser.py\", line 157, in parse\n",
      "    await self.nc._process_pong()\n",
      "  File \"/Users/godbrigero/Documents/BLITZ/.venv/lib/python3.12/site-packages/nats/aio/client.py\", line 1597, in _process_pong\n",
      "    future.set_result(True)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/futures.py\", line 260, in set_result\n",
      "    raise exceptions.InvalidStateError(f'{self._state}: {self!r}')\n",
      "asyncio.exceptions.InvalidStateError: CANCELLED: <Future cancelled>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    while True:\n",
    "        if cur_frame_clean_time > 30:\n",
    "            cur_frame_clean_time = 0\n",
    "            for image_id in image_id_map:\n",
    "                if time.time() - image_id_map[image_id][\"timestamp\"] > max_frame_age:\n",
    "                    image_id_map.pop(image_id)\n",
    "            \n",
    "        if abs(time.time() - last_reset_time) > 5:\n",
    "            total_time_per_image = 0\n",
    "            total_images = 0\n",
    "            last_reset_time = time.time()\n",
    "\n",
    "        total_images += 1\n",
    "            \n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        _, compressed_image = cv2.imencode(\".jpg\", frame)\n",
    "        \n",
    "        image_id = random.randint(0, 1000000)\n",
    "\n",
    "        msg = ImageMessage(\n",
    "            image=compressed_image.tobytes(),\n",
    "            camera_name=\"camera0\",\n",
    "            is_gray=False,\n",
    "            image_id=image_id,\n",
    "            height=frame.shape[0],\n",
    "            width=frame.shape[1],\n",
    "            timestamp=int(time.time() * 1000),\n",
    "        )\n",
    "\n",
    "        image_id_map[image_id] = {\"frame\": frame, \"timestamp\": time.time()}\n",
    "\n",
    "        await nt.publish(\"recognition/image_input\", msg.SerializeToString())\n",
    "        await nt.flush()\n",
    "        \n",
    "        print(\"Sent image to server\")\n",
    "\n",
    "        if not queue.empty() and image_id in image_id_map:\n",
    "            inference = await queue.get()\n",
    "            for inference in inference.inferences:\n",
    "                render_detections(image_id_map[image_id][\"frame\"], inference)\n",
    "                \n",
    "            cv2.imshow(\"frame\", image_id_map[image_id][\"frame\"])\n",
    "            cv2.waitKey(1)\n",
    "            total_time_per_image += time.time() - image_id_map[image_id][\"timestamp\"]\n",
    "            image_id_map.pop(image_id)\n",
    "        \n",
    "        time.sleep(total_time_per_image / total_images if total_images > 0 else 0.02)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting...\")\n",
    "except CancelledError:\n",
    "    print(\"Exiting...\")\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
